import sys

from pyspark.sql import SparkSession
from pyspark.sql.functions import lit, concat, min, floor, regexp_replace, concat_ws, count, collect_list, max
from pyspark.sql.types import *


def func():
    spark = SparkSession.builder.appName("clin_var").getOrCreate()
    sc = spark.sparkContext
    df = spark.read.option("header", "true").option("inferschema", "true").csv(
        "/mnt/data0/input/t2d_subgroups/t2d_clin_var.csv")
    # Open the studyID file generated by read_diagnosis_data
    studyidstest = spark.read.option("header", "true").option("inferschema", "true").csv(
        str(sys.argv[1]) + "_studyids_test.csv")
    studyidstrain = spark.read.option("header", "true").option("inferschema", "true").csv(
        str(sys.argv[1]) + "_studyids_train.csv")
    # Open the limitfile as generated by read_diagnosis_data
    limitfile = open(str(sys.argv[1]) + "limitfile.txt", "r")
    limit = limitfile.read()
    limit = float(limit)
    limitfile.close()
    # Read the median file as generated by read_diagnosis_data
    # Get the column names from the data
    cols = df.schema.names
    statuscols = ["weight_classification"]
    i = 0
    # Create a list of column names that don't contian the word diabetes
    while (i < len(cols)):
        if ((cols[i][len(cols[i]) - 6:] == "status") & (cols[i].find('diabetic') == -1)):
            statuscols.append(cols[i])
        i = i + 1
    # Create an empty schema for evaluating data
    schema = StructType([StructField("STUDYID", IntegerType(), True), StructField("CODE", StringType(), True),
                         StructField("DAYS_INDEX", IntegerType(), True)])
    # Create an empty dataframe to put values in
    vardf = spark.createDataFrame(sc.emptyRDD(), schema)
    i = 0
    # Loop through the status columns
    while (i < len(statuscols)):
        # Get the instances where the column is not null
        innerdf = df.where(df[statuscols[i]].isNotNull())
        # Rename columns for new dataframe
        innerdf = innerdf.select(innerdf["STUDYID"], innerdf["DAYS_VIS_INDEX"].alias("DAYS_INDEX"),
                                 concat(innerdf[statuscols[i]], lit("_"), lit(statuscols[i][0:15]), lit("_VAR")).alias(
                                     "CODE"))
        # Round down to create the year that a diagnosis occured in
        innerdf = innerdf.withColumn("DAYS_INDEX", floor((innerdf["DAYS_INDEX"].cast(FloatType())) / 365))
        # Count the number of times that each code and days_index occured for each patient
        innerdf = innerdf.groupby(innerdf['STUDYID'], innerdf['CODE'], innerdf['DAYS_INDEX']).count()
        # Find the maximum count for each studyid
        innerdfmax = innerdf.groupby(innerdf['STUDYID'], innerdf['DAYS_INDEX']).agg(max(innerdf['count']))
        # Rename the columns
        innerdfmax = innerdfmax.select(innerdfmax['STUDYID'], innerdfmax['DAYS_INDEX'],
                                       innerdfmax['max(count)'].alias('count'))
        # Join the IDs back together so that the maximum is there
        innerdf = innerdf.join(innerdfmax, on=['STUDYID', 'DAYS_INDEX', 'count'], how='inner')
        # Rename the columns
        innerdf = innerdf.select(innerdf['STUDYID'], innerdf['CODE'], innerdf['DAYS_INDEX'])
        # Get the first time that each lab result was given
        innerdf = innerdf.groupby([innerdf['STUDYID'], innerdf["CODE"]]).agg(min(innerdf['DAYS_INDEX']))
        # Rename the columns
        innerdf = innerdf.select(innerdf['STUDYID'], innerdf['CODE'], innerdf['min(DAYS_INDEX)'].alias('DAYS_INDEX'))
        # Filter such that the only data that remains is that that occured after diagnosis date and before the median date
        innerdf = innerdf.where((innerdf['DAYS_INDEX'] == 0))
        # Get the count of the diagnoses
        innerdfcount = innerdf.groupby(innerdf['CODE']).count()
        # Filter out diagnoses that occur in less than one percent of the population
        innerdfcount = innerdfcount.where(innerdfcount['COUNT'] > limit)
        # Get a list of codes that occur in that population
        codes = innerdfcount.select('CODE').distinct().rdd.flatMap(lambda x: x).collect()
        # Filter such that the dataframe only has those codes left in it
        innerdf = innerdf.filter(innerdf['CODE'].isin(codes))
        # Take empty spaces out of clinical variables - messes up graph creation
        innerdf = innerdf.withColumn('CODE', regexp_replace(innerdf['CODE'], " ", "_"))
        # Create testing and training dataset
        testinnerdf = innerdf.join(studyidstest, on=['STUDYID'], how='inner')
        traininnerdf = innerdf.join(studyidstrain, on=['STUDYID'], how='inner')
        testinnerdf = testinnerdf.where(testinnerdf['DAYS_INDEX_DX'] > testinnerdf['DAYS_INDEX'])
        traininnerdf = traininnerdf.where(traininnerdf['DAYS_INDEX_DX'] > traininnerdf['DAYS_INDEX'])
        testinnerdf = testinnerdf.select(testinnerdf['STUDYID'], testinnerdf['CODE'], testinnerdf['DAYS_INDEX'],
                                         testinnerdf['Diagnosed'])
        traininnerdf = traininnerdf.select(traininnerdf['STUDYID'], traininnerdf['CODE'], traininnerdf['DAYS_INDEX'],
                                           traininnerdf['Diagnosed'])
        if (i == 0):
            # Create a new dataframe
            testinnerdf.write.csv(str(sys.argv[1]) + '_clinvar_status_dataframe_test.csv', header="true",
                                  mode="overwrite")
            traininnerdf.write.csv(str(sys.argv[1]) + '_clinvar_status_dataframe_train.csv', header="true",
                                   mode="overwrite")
        else:
            # Append to existing dataframe
            testinnerdf.write.csv(str(sys.argv[1]) + '_clinvar_status_dataframe_test.csv', header="true", mode="append")
            traininnerdf.write.csv(str(sys.argv[1]) + '_clinvar_status_dataframe_train.csv', header="true",
                                   mode="append")
        i = i + 1
    spark.stop()


if __name__ == '__main__':
    func()

